{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "identical-satellite",
   "metadata": {},
   "source": [
    "# Entrenamiento de las redes profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-convenience",
   "metadata": {},
   "source": [
    "Entrenar una red con $10$ capas o más, y miles de conexiones, es difícil. Algunos problemas que pueden ocurrir son:\n",
    "\n",
    "* Gradientes que desaparecen o explotan: los gradientes de la función de activación pueden reducirse a cero o pueden crecer demasiado en el proceso de propagación hacia atrás, causando problemas en el entrenamiento de las capas más profundas en la red.\n",
    "\n",
    "\n",
    "* Cantidad insuficiente de datos para una red tan grande, o es demasiado difícil etiquetear todos los datos.\n",
    "\n",
    "\n",
    "* Entrenamiento muy lento.\n",
    "\n",
    "\n",
    "* Riesgo de *overfitting*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-saint",
   "metadata": {},
   "source": [
    "## Gradientes inestables\n",
    "\n",
    "En una red profunda muy amenudo los gradientes se reducen cuando avanzamos hacia las capas más profundas (más lejanas de la salida). Entonces la actualización de los pesos en las primeras capas es muy lenta, y la red nunca llega a una solución óptima. Esto se llama el problema de gradientes que se desvanecen (*vanishing gradients*).\n",
    "\n",
    "En algunas arquitecturas (redes recurrentes) el opuesto puede pasar: los gradientes crecen enormemente. Este es el problema de gradientes que explotan (*exploding gradients*).\n",
    "\n",
    "En general, las distintas capas en una red profunda aprenden con tasas muy diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-breath",
   "metadata": {},
   "source": [
    "En Glorot & Bengio (2010) identificaron algunas razones por tener el problema de gradientes que se desvanecen:\n",
    "\n",
    "* Consideramos una red con funciones de activación sigmoide y inicialización de los pesos con una Gaussiana de promedio $0$ y desviación estandar $1$.\n",
    "\n",
    "\n",
    "* La varianza de las salidas de cada capa es mucho mayor que la varianza de las entradas de cada capa. En la pase hacia adelante (*forward pass*) la varianza sigue creciendo después de cada capa, hasta que la función de activación se satura en la capa final.\n",
    "\n",
    "\n",
    "* Si la función de activación sigmoide es cerca a $0$ o $1$, los gradientes son muy pequeños, así que no hay mucho que se puede propagar hacia atrás. Además, el gradiente está diluido en cada capa en el algoritmo de *backpropagation*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-weapon",
   "metadata": {},
   "source": [
    "Se puede resolver el problema cambiando la inicialización de los pesos. Primero, hay que definir un par de números:\n",
    "\n",
    "* *fan*$_{in}$: número de entradas en una capa.\n",
    "* *fan*$_{out}$: número de neuronas en una capa.\n",
    "* *fan*$_{avg}$: promedio de los valores arriba.\n",
    "\n",
    "Incialización de Glorot (o Xavier):\n",
    "\n",
    "1. usar una distribución normal con promedio $0$ y varianza $\\sigma^2 = 1/\\text{fan}_{avg}$.\n",
    "\n",
    "\n",
    "2. Distribución uniforme entre $-r$ y $+r$ con $r=\\sqrt{3/\\text{fan}_{avg}}$.\n",
    "\n",
    "Ahora hay varias opciones, dependiende de la función de activación.\n",
    "\n",
    "![](figures_redes_profundas/table11-1.png)\n",
    "\n",
    "Por defecto, Keras ocupa Glorot, pero se puede cambiar:\n",
    "\n",
    "`keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")`\n",
    "\n",
    "Para usar He inicialización con una distribución uniforme pero basada en *fan*$_{avg}$ en vez de *fan*$_{in}$:\n",
    "\n",
    "```\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-picking",
   "metadata": {},
   "source": [
    "### Funciones de activación que no se saturan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-asian",
   "metadata": {},
   "source": [
    "El uso de la función sigmoide fue inspirado por las neuronas biológicas. Pero el problema de los *vanishing gradients* en redes profundas impulsó el uso de otras funciones, como por ejemplo la función ReLU (que no se satura para valores positivos).\n",
    "\n",
    "El problema con los ReLU es que durante el entrenamiento algunas neuronas pueden \"morirse\": sus salidas son siempre $0$. Este ocurre cuando la suma ponderada de entradas a la neurona es negativo para todas las instancias. El ReLU tiene gradiente cero para valores negativos, así que los pesos no cambian más y la neurona se muere.\n",
    "\n",
    "Hay una variante del ReLU que se llama *leaky ReLU*:\n",
    "\n",
    "$$\\text{LeakyReLU}_{\\alpha}(z) = \\text{max}(\\alpha z, z)$$\n",
    "\n",
    "El hiperparámetro $\\alpha$ determina cuanto \"filtra\" la función: es la pendiente para $z < 0$ y típicamente es igual a $0.01$. Así las neuronas nunca se mueren, aunque pueden existir en un \"coma\" prolongada...\n",
    "\n",
    "![](figures_redes_profundas/fig11-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-charter",
   "metadata": {},
   "source": [
    "En Clevert et al. (2015) propusieron una nueva función de activación que se llama *exponential linear unit* (ELU) que parece funciona mejor que cualquier variante del ReLU.\n",
    "\n",
    "$$\\text{ELU}_{\\alpha} (z) = \\begin{cases} \\alpha (\\exp(z) - 1) & z < 0 \\\\ z & z \\geq 0 \\end{cases}$$\n",
    "\n",
    "![](figures_redes_profundas/fig11-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-singles",
   "metadata": {},
   "source": [
    "Diferencias con el ELU, comparada con el ReLU.\n",
    "\n",
    "* Toma valores negativos cuando $z < 0$, que ayuda tener la salida promedia más cerca a $0$ y alivia el problema de *vanishing gradients*. El parámetro $\\alpha$ es tal que $\\text{ELU}(z) \\to \\alpha$ cuando $z \\to -\\infty$.\n",
    "\n",
    "\n",
    "* Tiene un gradiente no cero para $z < 0$ que elimina el problema de neuronas muertas.\n",
    "\n",
    "\n",
    "* Si $\\alpha = 1$ la función es suave en todos puntos, incluyendo $z=0$, que ayuda en descenso por gradiente.\n",
    "\n",
    "La desventaja que es que es más lento usar una red con ELU en vez de ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-placement",
   "metadata": {},
   "source": [
    "En Klambauer et al. (2017) descubrieron que si usamos una función que se llama SELU (*scaled ELU*) en un red con solamente capas densas y donde todas las capas ocultas ocupan SELU, la red muestra **auto normalización**: la salida de cada capa tiende a preservar un promedio de $0$ y una desciación estandar de $1$ durante el entrenamiento. Este resuelve por completo el problema de *exploding/vanishing gradients*.\n",
    "\n",
    "Hay condiciones para asegurar auto normalización:\n",
    "\n",
    "* Los *features* de las entradas deben ser estandarizados (promedio $0$, desviación estandar $1$)\n",
    "\n",
    "\n",
    "* Cada capa oculta debe ser incializada con inicialización de LeCun normal.\n",
    "\n",
    "\n",
    "* La arquitectura de la red debe ser secuencial. Si es recurrente o si tiene conexiones que saltan capas, como en el caso de *Wide & Deep*, auto normalización no está garantizada.\n",
    "\n",
    "\n",
    "* Auto normalización está garantizada solamente si las capas son densas (completamente conectadas). Algunos investigadores han notado que SELU puede mejorar el rendimiento de redes convolucionales también."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-grant",
   "metadata": {},
   "source": [
    "En resumen, podemos ordenar las funciones de activación, de la mejor hasta la peor:\n",
    "\n",
    "1. SELU\n",
    "2. ELU\n",
    "3. Leaky ReLU (y variantes)\n",
    "4. ReLU\n",
    "5. tanh\n",
    "6. Logística\n",
    "\n",
    "Muchas librerias ocupan ReLU por defecto, y están optimizadas para usar esa función, así que van a correr más rápido con esa.\n",
    "\n",
    "Para implementar LeakyRelU:\n",
    "\n",
    "```\n",
    "model = keras.models.Sequential([\n",
    "    [...]\n",
    "    keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    [...]\n",
    "])\n",
    "```\n",
    "\n",
    "Para SELU:\n",
    "\n",
    "```\n",
    "layer = keras.layers.Dense(10, activation=\"selu\", \n",
    "                           kernel_initializer=\"lecun_normal\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-toilet",
   "metadata": {},
   "source": [
    "## Normalización por lotes (*batch normalization*)\n",
    "\n",
    "Desarrollado por Ioffe y Szegedy (2015). Esta técnica es también para evitar el problema de los *vanishing/exploding gradients*.\n",
    "\n",
    "La idea es poner una operación en el modelo justo antes o después de la función de activación de cada capa oculta. Esta operación centra y normaliza las entradas, y después aplica un escalamiento y un desplazamiento al resultado.\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "1. $\\boldsymbol{\\mu}_B = \\frac{1}{m_B}\\sum_{i=1}^{m_B} \\boldsymbol{x}^{(i)}$\n",
    "\n",
    "\n",
    "2. $\\boldsymbol{\\sigma}_B^2 = \\frac{1}{m_B} \\sum_{i=1}^{m_B} \\left( \\boldsymbol{x}^{(i)} - \\boldsymbol{\\mu}_B \\right)^2$\n",
    "\n",
    "\n",
    "3. $\\hat{\\boldsymbol{x}}^{(i)} = \\frac{\\boldsymbol{x}^{(i)}-\\boldsymbol{\\mu}_B}{\\sqrt{\\boldsymbol{\\sigma}_B^2 + \\epsilon}}$\n",
    "\n",
    "\n",
    "4. $\\boldsymbol{z}^{(i)} = \\boldsymbol{\\gamma} \\otimes \\hat{\\boldsymbol{x}}^{(i)} + \\boldsymbol{\\beta}$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $\\boldsymbol{\\mu}_B$ es el vector de promedios de las entradas, evaluado sobre todo el *mini-batch*.\n",
    "\n",
    "\n",
    "* $\\boldsymbol{\\sigma}_B$ es el vector de desviaciones estandares de las entradas, evaluado sobre todo el *mini-batch*.\n",
    "\n",
    "\n",
    "* $m_B$ es el número de instancias en el *mini-batch*.\n",
    "\n",
    "\n",
    "* $\\hat{\\boldsymbol{x}}^{(i)}$ es el vector de entradas centradas y normalizadas para instancia $i$.\n",
    "\n",
    "\n",
    "* $\\boldsymbol{\\gamma}$ es el vector de parámetros de escala para la capa (un parámetro de escala por entrada).\n",
    "\n",
    "\n",
    "* $\\otimes$ representa multiplicación elemento-por-elemento.\n",
    "\n",
    "\n",
    "* $\\boldsymbol{\\beta}$ es el vector de desplazamientos para la capa.\n",
    "\n",
    "\n",
    "* $\\epsilon$ es un parámetro pequeño $(\\sim 10^{-5})$ para evitar división por cero.\n",
    "\n",
    "\n",
    "* $\\boldsymbol{z}^{(i)}$ es la salida de la operación de *batch normalization* (BN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-railway",
   "metadata": {},
   "source": [
    "En el momento de probar el modelo (usar el conjunto de prueba) típicamente no tenemos lotes de instancias, así que no podemos aplicar BN como está descrito arriba.\n",
    "\n",
    "Keras hace lo siguiente:\n",
    "\n",
    "1. Los vectores $\\boldsymbol{\\gamma}$ y $\\boldsymbol{\\beta}$ están aprendidos por *backpropagation*.\n",
    "\n",
    "2. Los vectores $\\boldsymbol{\\mu}$ y $\\boldsymbol{\\sigma}$ están estimados durante el proceso de entrenamiento usando un promedio móvil exponencial.\n",
    "\n",
    "Los autores del método demostraron que era posible usar funciones de activación que se saturan en una red profunda si BN está implementado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-batch",
   "metadata": {},
   "source": [
    "#### Implementación de BN en Keras\n",
    "\n",
    "Volvemos al ejemplo de Fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggressive-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alert-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beautiful-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prompt-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-lawyer",
   "metadata": {},
   "source": [
    "Cada capa de BN agrega $4$ parámetros por entrada: $\\boldsymbol{\\gamma}$, $\\boldsymbol{\\beta}$, $\\boldsymbol{\\mu}$ y $\\boldsymbol{\\sigma}$. Por ejemplo, la primera capa agrega $4 \\times 784 = 3136$ parámetros.\n",
    "\n",
    "Los parámetros $\\boldsymbol{\\mu}$ y $\\boldsymbol{\\sigma}$ no están afectados por *backpropagation* así que Keras se refiere a esos parámetros como \"no entrenable\" (hay $(3136+1200+400)/2 = 2368$ parámetros así)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lesser-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parámetros en la primera capa BN\n",
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-decade",
   "metadata": {},
   "source": [
    "Hay varios hiperparámetros asociados a BN. Dos de estos son:\n",
    "\n",
    "* `momentum`: usado en la actualización de los promedios móviles. Con un nuevo vector (de promedios o desviaciones estandares) $\\boldsymbol{v}$ el promedio está actualizado según $\\hat{\\boldsymbol{v}} \\leftarrow \\hat{\\boldsymbol{v}} \\times \\text{momentum} + \\boldsymbol{v} \\times (1-\\text{momentum})$. Un valor bueno es muy cerca a $1$.\n",
    "\n",
    "\n",
    "* `axis`: determina cual eje debería ser normalizado. Por defecto es igual a $-1$ (normaliza el último eje usando promedios y DE calculado de los otros ejes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-principle",
   "metadata": {},
   "source": [
    "*Batch normalization* es tan común en redes profundas que muchas veces las capas de BN no aparecen en los diagramas de los modelos, aunque están incluidos. La suposición es que hay una capa de BN después de cada capa oculta.\n",
    "\n",
    "[Zhang et al. (2019)](https://arxiv.org/abs/1901.09321) utilizaron una técnica nueva para la inicialización de los pesos, y lograron entrenar una red con 10.000 capas sin BN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-agenda",
   "metadata": {},
   "source": [
    "### *Gradient Clipping*\n",
    "\n",
    "Otra técnica para reducir el problema de gradientes que se explotan. La idea es simplemente \"cortar\" los gradientes si exceden un umbral. Es más usado para redes recurrentes.\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(clipvalue=1.0)`\n",
    "`model.compile(loss=\"mse\", optimizer=optimizer)`\n",
    "\n",
    "Este puede cambiar la dirección del gradiente. Por ejemplo si el vector original es `[0.9, 100.0]`, después será `[0.9, 1.0]`.\n",
    "\n",
    "Se puede evitar ese problema usando `clipnorm` que corta el gradiente si la norma $\\mathcal{l}_2$ excede el umbral. Por ejemplo `[0.9, 100.0]` después será `[0.00899964, 0.9999595]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-survivor",
   "metadata": {},
   "source": [
    "## Otros optimizadores\n",
    "\n",
    "El entrenamiento de una red profunda puede ser muy lento. Hasta ahora hemos visto $3$ maneras de acelerar el proceso:\n",
    "\n",
    "* Aplicar una buena estrategia de inicialización.\n",
    "\n",
    "\n",
    "* Utilizar una buena función de activación.\n",
    "\n",
    "\n",
    "* *Batch normalization*\n",
    "\n",
    "También existe la opción de usar una parte de un modelo ya entrenado (ver el libro).\n",
    "\n",
    "Otra opción es cambiar el optimizador..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-singer",
   "metadata": {},
   "source": [
    "### Optimización momentum\n",
    "\n",
    "En este método los gradientes están usados para *acelerar* el movimiento en el espacio de la función de costo. Hay un nuevo hiperparámetro $\\beta$ que corresponde a una \"fricción\" para frenar el movimiento. $\\beta = 0$ (fricción alta), $\\beta = 1$ (sin fricción).\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "1. $\\boldsymbol{m} \\leftarrow \\beta\\boldsymbol{m} - \\eta \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})$\n",
    "\n",
    "2. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\boldsymbol{m}$\n",
    "\n",
    "Implementación:\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-portland",
   "metadata": {},
   "source": [
    "### Gradiente acelerado de Nesterov (NAG)\n",
    "\n",
    "En esta variante el gradiente está medida no en la posición local $\\boldsymbol{\\theta}$ sino que un poco más adelante en la dirección del momentum, en $\\boldsymbol{\\theta} + \\beta \\boldsymbol{m}$.\n",
    "\n",
    "1. $\\boldsymbol{m} \\leftarrow \\beta \\boldsymbol{m} - \\eta \\nabla_{\\boldsymbol{\\theta}} J (\\boldsymbol{\\theta} + \\beta \\boldsymbol{m})$\n",
    "\n",
    "2. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\boldsymbol{m}$\n",
    "\n",
    "![](figures_redes_profundas/fig11-6.png)\n",
    "\n",
    "Implementación:\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-somewhere",
   "metadata": {},
   "source": [
    "### AdaGrad\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "1. $\\boldsymbol{s} \\leftarrow \\boldsymbol{s} + \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) \\otimes \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})$\n",
    "\n",
    "2. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) \\oslash \\sqrt{\\boldsymbol{s} + \\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-young",
   "metadata": {},
   "source": [
    "El primer paso acumula los gradientes cuadrados en los elementos del vector $\\boldsymbol{s}$. Es equivalente a:\n",
    "\n",
    "$$s_i \\leftarrow s_i + \\left( \\frac{\\partial J(\\boldsymbol{\\theta})}{\\partial \\theta_i} \\right)^2$$\n",
    "\n",
    "Si la función de costo es muy inclinada en la dirección que corresponde al parámetro $\\theta_i$, el elemento $s_i$ crecerá en cada iteración.\n",
    "\n",
    "El segundo paso aplica un factor al vector del gradiente ($\\oslash$ significa división elemento-por-elemento). Es equivalente a:\n",
    "\n",
    "$$\\theta_i \\leftarrow \\theta_i - \\eta \\left( \\frac{\\partial J(\\boldsymbol{\\theta})}{\\partial \\theta_i} \\right) \\frac{1}{\\sqrt{s_i + \\epsilon}}$$\n",
    "\n",
    "Entonces la tasa de aprendizaje está reducida más rápidamente en las direcciones más inclinadas. Así que tiene una tasa de aprendizaje **adaptativa**.\n",
    "\n",
    "![](figures_redes_profundas/fig11-7.png)\n",
    "\n",
    "De hecho AdaGrad funciona bien para modelos simples, pero no es apto para una red profunda: la tasa de aprendizaje está reducida tanto que el algoritmo no llega al mínimo. Pero ayuda en entender los otros optimizadores adaptativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-processing",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "\n",
    "El problema de AdaGrad es que reduce su velocidad demasiado. RMSProp evita este problema por usar solamente los gradientes de las iteraciones más recientes (en vez de todos desde el comienzo del entrenamiento).\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "1. $\\boldsymbol{s} \\leftarrow \\beta \\boldsymbol{s} + (1 - \\beta) \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) \\otimes \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})$\n",
    "\n",
    "2. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) \\oslash \\sqrt{\\boldsymbol{s} + \\epsilon}$\n",
    "\n",
    "El parámetro $\\beta$ (tasa de decaimiento) típicamente es igual a $0.9$.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "`optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)`\n",
    "\n",
    "`rho` aquí corresponde a $\\beta$ arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-mirror",
   "metadata": {},
   "source": [
    "### Optimización de Adam y Nadam\n",
    "\n",
    "Adam (*adaptive moment estimation*) combina las ideas de optimización de momentum y RMSProp.\n",
    "\n",
    "* Como optimización de momentum, sigue un promedio que decae exponencialmente de gradientes pasados.\n",
    "* Como optimización RMSProp, sigue un promedio que decae exponencialmente de gradientes cuadrados pasados.\n",
    "\n",
    "Algoritmo:\n",
    "\n",
    "1. $\\boldsymbol{m} \\leftarrow \\beta_1 \\boldsymbol{m} - (1 - \\beta_1) \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})$\n",
    "\n",
    "\n",
    "2. $\\boldsymbol{s} \\leftarrow \\beta_2 \\boldsymbol{s} + (1 - \\beta_2) \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) \\otimes \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})$\n",
    "\n",
    "\n",
    "3. $\\hat{\\boldsymbol{m}} \\leftarrow \\frac{\\boldsymbol{m}}{1-\\beta_2^t}$\n",
    "\n",
    "\n",
    "4. $\\hat{\\boldsymbol{s}} \\leftarrow \\frac{\\boldsymbol{s}}{1-\\beta_2^t}$\n",
    "\n",
    "\n",
    "5. $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\eta \\hat{\\boldsymbol{m}} \\oslash \\sqrt{\\hat{\\boldsymbol{s}} + \\epsilon}$\n",
    "\n",
    "$t$ significa el número de iteración.\n",
    "\n",
    "$\\boldsymbol{m}$ y $\\boldsymbol{s}$ están inicializados en $0$, así que tienen un sesgo hacia $0$ al principio del entrenamiento. Pasos 3 y 4 son para dar un *boost* a estos vectores cuando el entrenamiento comienza.\n",
    "\n",
    "Típicamente $\\beta_1 = 0.9$ y $\\beta_2 = 0.999$.\n",
    "\n",
    "Implementación:\n",
    "\n",
    "`optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-magic",
   "metadata": {},
   "source": [
    "#### Variantes\n",
    "\n",
    "**AdaMax**: reemplaza paso 2 por $\\boldsymbol{s} \\leftarrow \\max(\\beta_2 \\boldsymbol{s}, \\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})$.\n",
    "\n",
    "**Nadam**: Adam + Nesterov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-romania",
   "metadata": {},
   "source": [
    "Todas las técnicas de optimización que hemos visto utilizan derivadas parciales de primer orden (**Jacobianos**).\n",
    "\n",
    "Hay técnicas en la literatura que aplican derivadas parciales de segundo orden (**Hessianas**).\n",
    "\n",
    "El problema es que hay $n^2$ hessianas por salida (donde $n$ es el número de parámetros), comparado con $n$ jacobianos.\n",
    "\n",
    "Para una red profunda hay miles de parámetros, así que muchas veces las hessianas no caben en la memoria..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-theta",
   "metadata": {},
   "source": [
    "### Planificación de la tasa de aprendizaje\n",
    "\n",
    "![](figures_redes_profundas/fig11-8.png)\n",
    "\n",
    "* Ley de potencia: $\\eta(t) = \\eta_0 / (1+t/s)^c$. Típicamente $c=1$. Después de $s$ iteraciones $\\eta = \\eta_0/2$, después de $2s$ iteraciones $\\eta = \\eta_0/3$ etc.\n",
    "\n",
    "\n",
    "* Exponencial: $\\eta(t) = \\eta_0 0.1^{t/s}$. $\\eta$ reduce por un factor de $10$ cada $s$ iteraciones.\n",
    "\n",
    "\n",
    "* Constante por partes: usar $\\eta_0 = 0.1$ (por ejemplo) para $5$ iteraciones, después $\\eta_1 = 0.001$ para $50$ iteraciones, etc.\n",
    "\n",
    "\n",
    "* Rendimiento: medir el error de validación cada $N$ iteraciones, reducir la tasa de aprendizaje por un factor $\\lambda$ cuando el error acaba de bajar.\n",
    "\n",
    "\n",
    "* *1cycle*: Smith (2018). Aumenta la tasa inicial linealmente de $\\eta_0$ a $\\eta_1$, en la primera mitad del entrenamiento. Después reduce $\\eta$ hasta $\\eta_0$ en la segunda mitad. Elegimos $\\eta_1$ usando el mismo método descrito antes para encontrar la tasa óptima. Si usamos momentum, comenzamos con un momentum alto ($0.95$), se reduce a $0.85$ linealmente en la primera mitad, y sube al máximo de nuevo en la segund mitad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-oxford",
   "metadata": {},
   "source": [
    "Implementación:\n",
    "\n",
    "* Ley de potencia: `optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)`. `decay` es la inversa de $s$, y $c=1$.\n",
    "\n",
    "* Exponencial: se puede definir una función que retorna otra función que define la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "    \n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, [...], callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-honey",
   "metadata": {},
   "source": [
    "`LearningRateScheduler` actualizará `learning_rate` al principio de cada época."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-dairy",
   "metadata": {},
   "source": [
    "* Constante por partes: se puede crear una función, como lo que hicimos para la exponencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constat_fn(epoch):\n",
    "    if (epoch < 5):\n",
    "        return 0.01\n",
    "    elif (epoch < 15):\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-leather",
   "metadata": {},
   "source": [
    "* Rendimiento: se puede usar el *callback* `ReduceLROnPlateau`\n",
    "\n",
    "`lr_scheduler = keras.callbacks.ReduceLROnPlateua(factor=0.5, patience=5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-replica",
   "metadata": {},
   "source": [
    "Otra opción es usar los *schedules* disponibles en `keras.optimizers.schedules`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32 #número de iteraciones en 20 épocas (lote = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-calculation",
   "metadata": {},
   "source": [
    "Para implementar *1cycle* también se puede crear un *callback* para actualizar la tasa de aprendizaje en cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-genome",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "\n",
    "Vamos a ver algunas formas de regularizar redes profundas:\n",
    "\n",
    "* Regularización $\\mathcal{l}_1$ y $\\mathcal{l}_2$.\n",
    "\n",
    "\n",
    "* *Dropout*\n",
    "\n",
    "\n",
    "* *Max-norm*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-witch",
   "metadata": {},
   "source": [
    "### Regularización $\\mathcal{l}_1$ y $\\mathcal{l}_2$\n",
    "\n",
    "Para $\\mathcal{l}_2$ podemos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-president",
   "metadata": {},
   "source": [
    "Esto aplicará regularización $\\mathcal{l}_2$ con un factor de $0.01$ a los pesos de la capa. La función `l2()` retorna un regularizador que está llamado en cada iteración durante el entrenamiento, y después está sumado a la función de costo final.\n",
    "\n",
    "Para $\\mathcal{l}_1$: `keras.regularizers.l1()`. En este caso varios pesos podrían acercarse al valor $0$.\n",
    "\n",
    "Para ambas regularizaciones: `keras.regularizers.l1_l2()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-miller",
   "metadata": {},
   "source": [
    "Un truco para no tener que repetir los argumentos a `Dense` en cada capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\",\n",
    "                     kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-window",
   "metadata": {},
   "source": [
    "### *Dropout*\n",
    "\n",
    "Este es un método muy popular de regularizar redes profundas.\n",
    "\n",
    "La idea es: en cada iteración de entrenamiento cada neurona (excluyendo las neuronas de salida) tiene una probabilidad $p$ de estar desactivada (*dropped out*).\n",
    "\n",
    "La tasa de *dropout*, $p$, tiene un valor típicamente entre $10\\%$ y $50\\%$ (menor en redes recurrentes, mayor en redes convolucionales).\n",
    "\n",
    "![](figures_redes_profundas/fig11-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-plasma",
   "metadata": {},
   "source": [
    "Se puede interpretar el uso de *dropout* como el entrenamiento de muchas redes diferentes (pero relacionadas). La red final es como el ensamble de todas estas redes.\n",
    "\n",
    "Un detalle importante: supongamos que $p = 0.5$ ($50\\%$). Durante el proceso de evaluación una neurona será conectada al doble del número de neuronas conectadas en el entrenamiento. \n",
    "\n",
    "Por eso, hay que multiplicar los pesos en las conexiones de entrada da cada neurona por $0.5$. Si no, cada neurona recibirá una señal dos veces mayor (en evaluación) comparado con el entrenamiento, y es muy probable que no tendrá un rendimiento bueno.\n",
    "\n",
    "En general, hay que multiplicar cada peso de entrada por la *keep probability* $(1-p)$ después del entrenamiento (Keras se encarga de esto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "utility-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "short-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dated-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "living-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.5757 - accuracy: 0.8037 - val_loss: 0.3829 - val_accuracy: 0.8610\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4213 - accuracy: 0.8468 - val_loss: 0.3523 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-battle",
   "metadata": {},
   "source": [
    "**Ojo**: *dropout* está activado solamente durante el entrenamiento, así comparando la perdida de entrenamiento con la de validación podría ser engañoso... Un modelo podría *overfit* los datos de entrenamiento, pero tener perdidas similares entre entrenamiento y validación. Hay que evaluar la perdida de entrenamiento después, sin *dropout*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-virgin",
   "metadata": {},
   "source": [
    "Para usar *dropout* con una red auto normalizada (usando SELU) hay que usar *alpha dropout*. *Dropout* normal destruye la auto normalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-gibson",
   "metadata": {},
   "source": [
    "### *Dropout* de Monte Carlo (MC)\n",
    "\n",
    "Con MC *Dropout* se puede mejorar el rendimiento de un modelo ya entrenado con *dropout*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "peaceful-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-participation",
   "metadata": {},
   "source": [
    "Hacemos $100$ predicciones en el conjunto de prueba, con `training=True` para asegurar que la capa de *dropout* está activa, y después combinamos las predicciones.\n",
    "\n",
    "Ya que *dropout* está activo, todas las predicciones son diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-blogger",
   "metadata": {},
   "source": [
    "`predict()` retorna una matriz con una fila por instancia y una columna por clase. Con $10000$ instancias en el conjunto de prueba y $10$ clases, la matriz tendrá una forma de $10000 \\times 10$.\n",
    "\n",
    "Combinamos $100$ matrices así, entonces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "popular-independence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-buying",
   "metadata": {},
   "source": [
    "Calculando el promedio con `axis=0` obtenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "flying-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-swimming",
   "metadata": {},
   "source": [
    "Este es lo que tendríamos haciendo una predicción con el modelo para cada instancia en el conjunto de prueba.\n",
    "\n",
    "El promedio con *dropout* es una estimación de Monte Carlo (muestra aleatoria) que es típicamente más confiable que el resultado de una sola predicción sin *dropout*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "miniature-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.22, 0.  , 0.77]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacterial-tonight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.31, 0.  , 0.67]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-trading",
   "metadata": {},
   "source": [
    "Con el resultado de MC *dropout* tenemos una estimación más razonable, y nos da más información sobre posibles confusiones del modelo.\n",
    "\n",
    "Podemos medir la incertidumbre con la desviación estandar en las predicciones de la versión MC *dropout*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eight-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.21, 0.  , 0.22]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stock-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_scaled), axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "japanese-browse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8568"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-coral",
   "metadata": {},
   "source": [
    "Si el modelo incluye otras capas que tienen un comportamiento especial durante el entrenamiento (e.g. `BatchNormalization`) no podemos usar modo `training=True`. Tenemos que reemplazar las capas de `Dropout` por capas de `MCDropout` definidas en el código abajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-student",
   "metadata": {},
   "source": [
    "### Regularización *max-norm*\n",
    "\n",
    "Para cada neurona, restringe los pesos de las conexiones de entrada tal que $|| \\boldsymbol{w} ||_2 \\leq r$ donde $r$ es el parámetro *max-norm* y $|| \\cdot ||_2$ es la norma $\\mathcal{l}_2$.\n",
    "\n",
    "Está implementado por calcular $|| \\boldsymbol{w} ||_2$ después de cada iteración y modificar $\\boldsymbol{w}$ si es necesario con:\n",
    "\n",
    "$\\boldsymbol{w} \\leftarrow \\boldsymbol{w} \\frac{r}{|| \\boldsymbol{w} ||_2}$\n",
    "\n",
    "Implementación en Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-banana",
   "metadata": {},
   "source": [
    "Se puede definir funciones para implementar restricciones customizadas. También podemos restringir los *bias* con `bias_constraint`.\n",
    "\n",
    "La función `max_norm()` tiene un argumento `axis` (por defecto igual a $0$). Para capas convolucionales hay que aplicar el `axis` correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-elder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
