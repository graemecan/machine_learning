{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-dallas",
   "metadata": {},
   "source": [
    "# Reducción de dimensionalidad\n",
    "\n",
    "Muchos problemas de *machine learning* involucran miles o millones de *features* para cada instancia de entrenamiento. Este resulta en algoritmos lentos y dificultad en encontrar una solución buena.\n",
    "\n",
    "Se refiere a este problema como la **maldición de dimensionalidad**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-charger",
   "metadata": {},
   "source": [
    "En muchos casos es posible reducir el número de *features*.\n",
    "\n",
    "Por ejemplo, con los datos de MNIST todos los pixeles en el borde de la imagen son blancos - podríamos eliminar estos pixeles.\n",
    "\n",
    "También hay mucha correlación entre pixeles vecinos, así que podríamos unir pixeles.\n",
    "\n",
    "Reducción del número de *features* también es muy útil para **visualización de datos**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-russian",
   "metadata": {},
   "source": [
    "#### Peculiaridades de altas dimensiones...\n",
    "\n",
    "![](figures_dimensionalidad/fig8-1.png)\n",
    "\n",
    "Es muy difícil imaginar un hipercubo de 1000 dimensiones... Además nuestra intuición que viene de $3$ dimensiones no sirve mucho en este caso.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "* Si elegimos un punto aleatorio en una cuadrada unitaria (con aristas de longitud $1$), estará a una distancia menor que 0.001 del borde con una probabilidad de 0.4%.\n",
    "* En un hipercubo de 10,000 dimensiones, cuál sería la probabilidad de elegir un punto tan cerca al borde?\n",
    "\n",
    "<details>\n",
    "    <summary>Respuesta</summary>\n",
    "    <p>99.999999%</p>\n",
    "</details>\n",
    "\n",
    "* Si elegimos dos puntos aleatoriamente en una cuadrada unitaria, la distancia entre los dos puntos será, en promedio, $\\sim 0.52$.\n",
    "* Dos puntos aleatorios en un cubo unitario 3D tendrán una separación de $\\sim 0.66$.\n",
    "* En el caso de un hipercubo en 1,000,000 dimensiones?\n",
    "\n",
    "<details>\n",
    "    <summary>Respuesta</summary>\n",
    "    <p>$\\sim 408.25$</p>\n",
    "</details>\n",
    "\n",
    "Entonces, en datos de altas dimensiones, la mayoría de los puntos tendrán una separación grande. Este podría complicar las predicciones del modelo, ya que ningún punto es cerca a otro..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-economics",
   "metadata": {},
   "source": [
    "## Métodos principales para reducción de dimensiones\n",
    "\n",
    "### Proyección\n",
    "\n",
    "En muchos datos las instancias no están distribuidas uniformemente a través del espacio de *features*. Muchos *features* son casi constantes y otros están altamente correlacionados.\n",
    "\n",
    "Este significa que las instancias pertenecen a un sub-espacio del espacio de *features* que tiene menos dimensiones.\n",
    "\n",
    "![](figures_dimensionalidad/fig8-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-stress",
   "metadata": {},
   "source": [
    "En este ejemplo podemos proyeccionar las instancias al plano:\n",
    "\n",
    "![](figures_dimensionalidad/fig8-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-nitrogen",
   "metadata": {},
   "source": [
    "Pero para otros datos proyección no sirve, ya que el sub-espacio puede girar y doblar, por ejemplo en el caso del conjunto de datos sintético que se llama el *Swiss roll*:\n",
    "\n",
    "| ![](figures_dimensionalidad/fig8-4.png) | ![](figures_dimensionalidad/swiss_roll.jpg) |\n",
    "|-----------------------------------------|---------------------------------------------|\n",
    "\n",
    "Una proyección de estos datos resultará en aplastar varias capas de los datos y mezclarlas.\n",
    "\n",
    "![](figures_dimensionalidad/fig8-5.png)\n",
    "\n",
    "Lo que queremos hacer es desenrollar los datos..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-evans",
   "metadata": {},
   "source": [
    "### Aprendizaje de variedad (*manifold learning*)\n",
    "\n",
    "El *Swiss roll* es un ejemplo de una **variedad**.\n",
    "\n",
    "Una variedad es un concepto de la matemática (muy usado en la relatividad general). Se puede definir una variedad como un sub-espacio dentro de un espacio de más dimensiones que puede tener una forma geométrica arbitraria, pero que **localmente** se ve como un hiperplano.\n",
    "\n",
    "Varios algoritmos de reducción de dimensión funcionan por modelar la variedad donde pertenecen las instancias - se llama *manifold learning*.\n",
    "\n",
    "El método se basa en la suposición de la variedad (*manifold assumption*, *manifold hypothesis*) que dice que la mayoría de conjuntos de datos de alta dimensión del mundo real tienen instancias en una variedad de dimensión baja.\n",
    "\n",
    "Por ejemplo, los datos de MNIST: hay similitudes entre todas las imagenes. Si generamos intensidades de $28 \\times 28$ pixeles aleatoriamente, solamente una fracción infinitesimal de las imagenes van a corresponder a las imagenes del conjunto de MNIST.\n",
    "\n",
    "Otra suposición es que la tarea de clasificación o regresión será más fácil expresada en el sub-espacio de la variedad, pero no es siempre así...\n",
    "\n",
    "| ![](figures_dimensionalidad/fig8-6.png) |\n",
    "|-----------------------------------------|\n",
    "| El límite de decisión es más simple en el sub-espacio en el caso de arriba, pero no así en el caso de abajo. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-obligation",
   "metadata": {},
   "source": [
    "## PCA (*Principal Component Analysis*)\n",
    "\n",
    "PCA identifica el hiperplano más cerca a los datos, y después proyecciona los datos a este plano.\n",
    "\n",
    "**BASED ON SVD, SO I'D BETTER EXPLAIN THIS IN MORE DETAIL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-imagination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
